{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04038f13",
   "metadata": {},
   "source": [
    "# Molecular design ML-in-the-loop workflow with Parsl\n",
    "\n",
    "This notebook demonstrates a simple molecular design application where we use machine learning to guide which computations we perform.\n",
    "The objective of this application is to identify which molecules have the largest ionization energies (IE, the amount of energy required to remove an electron). \n",
    "\n",
    "IE can be computed using various simulation packages (here we use [xTB](https://xtb-docs.readthedocs.io/en/latest/contents.html) ); however, execution of these simulations is expensive, and thus, given a finite compute budget, we must carefully select which molecules to explore. We use machine learning to predict high IE molecules based on previous computations (a process often called [active learning](https://pubs.acs.org/doi/abs/10.1021/acs.chemmater.0c00768)). We iteratively retrain the machine learning model to improve the accuracy of predictions. The resulting ML-in-the-loop workflow proceeds as follows. \n",
    "\n",
    "![workflow](./figures/workflow.svg)\n",
    "\n",
    "In this notebook, we use Parsl to execute functions (simulation, model training, and inference) in parallel. Parsl allows us to establish dependencies in the workflow and to execute the workflow on arbitrary computing infrastructure, from laptops to supercomputers. We show how Parsl's integration with Python's native concurrency library (i.e., [`concurrent.futures`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)) let you write applications that dynamically respond to the completion of asynchronous tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb5a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from chemfunctions import compute_vertical\n",
    "from concurrent.futures import as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.app.python import PythonApp\n",
    "from parsl.app.app import python_app\n",
    "from parsl.config import Config\n",
    "from time import monotonic\n",
    "from random import sample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import parsl\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066d4dd-bcd5-4426-b223-62e80166a87c",
   "metadata": {},
   "source": [
    "Configuration for the computing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf302e6-3790-4ad9-8c1d-e24e9c9482ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = min(4, os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0d354",
   "metadata": {},
   "source": [
    "## Define problem\n",
    "\n",
    "We first define configuration parameters for the app, specifically the search space of molecules (selected randomly from the QM9 database) and parameters controlling the optimization algorithm (the number of initial simulations, total moleucles to be evaluated, and the number of molecules to be evaluated in a batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5cb8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = pd.read_csv('data/QM9-search.tsv', delim_whitespace=True)  # Our search space of molecules\n",
    "# search_space = search_space.iloc[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf97d00-283d-4532-a34e-a96743ec124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemfunctions import compute_rdkit_descriptors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler # For normalizing inputs\n",
    "import pickle as pk\n",
    "\n",
    "feats = [compute_rdkit_descriptors(sml) for sml in search_space['smiles']]\n",
    "st = StandardScaler()\n",
    "feats_scaled = st.fit_transform(feats)\n",
    "pk.dump(st, open(\"st.pkl\",\"wb\"))\n",
    "pca = PCA(n_components=15)\n",
    "result = pca.fit(feats_scaled) # Assume X is having more than 2 dimensions    \n",
    "pk.dump(pca, open(\"pca.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f170e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_count: int = 8  # Number of calculations to run at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad59f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_count: int = 64   # Number of molecules to evaluate in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3bed4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size: int = 4  # Number of molecules to evaluate in each batch of simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f939d",
   "metadata": {},
   "source": [
    "## Set up Parsl\n",
    "\n",
    "We now configure Parsl to make use of available resources. In this case we configure Parsl to run on the local machine with two workers. One of the benefits of Parsl is that we can change this configuration to make use of different resources without modifying the following workflow. For example, we can configure Parsl to use more cores on the local machine or to use many nodes on a Supercomputer or Cloud. The [Parsl website](https://parsl.readthedocs.io/en/stable/userguide/configuring.html) describes how Parsl can be configured for different resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7222dc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f29dd0bd580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(\n",
    "    executors=[HighThroughputExecutor(\n",
    "        max_workers=4, # Allows a maximum of two workers\n",
    "        cpu_affinity='block' # Prevents workers from using the same cores\n",
    "    )]\n",
    ")\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08379a3",
   "metadata": {},
   "source": [
    "## Make an initial dataset\n",
    "\n",
    "We need data to train our ML models. We'll do that by selecting a set of molecules at random from our search space, performing some simulations on those molecules, and training on the results.\n",
    "\n",
    "In [`chemfunctions.py`](./chemfunctions.py), we have defined a function `compute_vertical` that computes the \"vertical ionization energy\" of a molecule (a measure of how much energy it takes to strip an electron off the molecule). `compute_vertical` takes a string representation of a molecule in [SMILES format](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) as input and returns the ionization energy as a float. Under the hood, it is running [xTB](https://xtb-docs.readthedocs.io/en/latest/contents.html) to perform a series of quantum chemistry computations.\n",
    "\n",
    "### Execute a first simulation\n",
    "We need to prepare this function to run with Parsl. All we need to do is wrap this function with Parsl's `python_app`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b97999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.app.python.PythonApp at 0x7f29da638a60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_vertical_app = python_app(compute_vertical)\n",
    "compute_vertical_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36525082",
   "metadata": {},
   "source": [
    "This new object is a Parsl `PythonApp`. It can be invoked like the original function, but instead of immediately executing, the function may be run asynchronously by Parsl. Instead of the result, the call will immediately return a `Future` which we can use to retrieve the result or obtain the status of the running task.\n",
    "\n",
    "For example, invoking the `compute_verticle_app` with the SMILES for water, `O`, returns a Future and schedules `compute_verticle` for execution in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c39daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AppFuture at 0x7f29da638820 state=pending>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future = compute_vertical_app('O') #  Run water as a demonstration (O is the SMILES for water)\n",
    "future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85cfad",
   "metadata": {},
   "source": [
    "We can access the result of this computation by asking the future for the `result()`. If the computation isn't finished yet, then the call to `.result()` will block until the result is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921c7a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ionization energy of O is 0.43 Ha\n"
     ]
    }
   ],
   "source": [
    "ie = future.result()\n",
    "print(f\"The ionization energy of {future.task_def['args'][0]} is {ie:.2f} Ha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085a991",
   "metadata": {},
   "source": [
    "### Scale the simulation\n",
    "\n",
    "It is trivial now to scale our simulation and run it for several different molecules and gather their results.\n",
    "\n",
    "We use a standard Python loop to submit a set of simulations for execution. As above, each invocation returns a `Future` immediately, so this code should finish within a few milliseconds.\n",
    "\n",
    "Because we never call `.result()`, this code does not wait for any results to be ready. Instead, Parsl is running the computations in the background. Parsl manages sending work to each worker process, collecting results, and feeding new work to workers as new tasks are submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c74a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted 8 calculations to start with\n",
      "CPU times: user 11.3 ms, sys: 5.09 ms, total: 16.4 ms\n",
      "Wall time: 13.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "smiles = search_space.sample(initial_count)['smiles']\n",
    "futures = [compute_vertical_app(s) for s in smiles]\n",
    "print(f'Submitted {len(futures)} calculations to start with')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda3b23",
   "metadata": {},
   "source": [
    "The futures produced by Parsl are based on Python's [native \"Future\"](https://docs.python.org/3/library/concurrent.futures.html#future-objects) object,\n",
    "so we can use Python's utility functions to work with them.\n",
    "\n",
    "As an example, we can build a loop that submits new computations if previous ones fail. This happens not too infrequently with our simulation application.\n",
    "\n",
    "We use `as_completed` to take an iterable (in this case a list) of futures and to yeild as each future completes.  Thus, we progress and handle each simulation as it completes\n",
    "\n",
    "We also use, `Future.exception()` rather than the similar `Future.result()`. `Future.exception()` behaves similarly in that it will block until the relevant task is completed, but rather than return the result, it returns any exception that was raised during execution (or `None` if not). In this case, if the future returns an exception we simply pick a new molecule and re-execute the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac26a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation for N=COCC#C succeeded\n",
      "Computation for COCC(=O)C#C succeeded\n",
      "Computation for O=CCCC=O succeeded\n",
      "Computation for NC(=O)NC(N)=O succeeded\n",
      "Computation for CC(=O)C#CC#C succeeded\n",
      "Computation for CC(=O)CCC=O succeeded\n",
      "Computation for NC(=O)CC1CC1 succeeded\n",
      "Computation for C1NC11COC1 succeeded\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "while len(futures) > 0: \n",
    "    # First, get the next completed computation from the list\n",
    "    future = next(as_completed(futures))\n",
    "    \n",
    "    # Remove it from the list of still-running tasks\n",
    "    futures.remove(future)\n",
    "    \n",
    "    # Get the input \n",
    "    smiles = future.task_def['args'][0]\n",
    "    \n",
    "    # Check if the run completed successfully\n",
    "    if future.exception() is not None:\n",
    "        # If it failed, pick a new SMILES string at random and submit it    \n",
    "        print(f'Computation for {smiles} failed, submitting a replacement computation')\n",
    "        smiles = search_space.sample(1).iloc[0]['smiles'] # pick one molecule\n",
    "        new_future = compute_vertical_app(smiles) # launch a simulation in Parsl\n",
    "        futures.append(new_future) # store the Future so we can keep track of it\n",
    "    else:\n",
    "        # If it succeeded, store the result\n",
    "        print(f'Computation for {smiles} succeeded')\n",
    "        train_data.append({\n",
    "            'smiles': smiles,\n",
    "            'ie': future.result(),\n",
    "            'batch': 0,\n",
    "            'time': monotonic()\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f373bbc",
   "metadata": {},
   "source": [
    "We now have an initial set of training data. We load this training data into a pandas `DataFrame` containing the randomly samples molecules alongside the simulated ionization energy (`ie`). In addition, the code above has stored some metadata (`batch` and `time`) which we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f15684d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>ie</th>\n",
       "      <th>batch</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N=COCC#C</td>\n",
       "      <td>0.358816</td>\n",
       "      <td>0</td>\n",
       "      <td>2.270266e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCC(=O)C#C</td>\n",
       "      <td>0.348168</td>\n",
       "      <td>0</td>\n",
       "      <td>2.270268e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=CCCC=O</td>\n",
       "      <td>0.365012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.270276e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC(=O)NC(N)=O</td>\n",
       "      <td>0.370995</td>\n",
       "      <td>0</td>\n",
       "      <td>2.270285e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(=O)C#CC#C</td>\n",
       "      <td>0.379496</td>\n",
       "      <td>0</td>\n",
       "      <td>2.270287e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CC(=O)CCC=O</td>\n",
       "      <td>0.359844</td>\n",
       "      <td>0</td>\n",
       "      <td>2.270297e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NC(=O)CC1CC1</td>\n",
       "      <td>0.358055</td>\n",
       "      <td>0</td>\n",
       "      <td>2.270300e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C1NC11COC1</td>\n",
       "      <td>0.356743</td>\n",
       "      <td>0</td>\n",
       "      <td>2.270301e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          smiles        ie  batch          time\n",
       "0       N=COCC#C  0.358816      0  2.270266e+06\n",
       "1    COCC(=O)C#C  0.348168      0  2.270268e+06\n",
       "2       O=CCCC=O  0.365012      0  2.270276e+06\n",
       "3  NC(=O)NC(N)=O  0.370995      0  2.270285e+06\n",
       "4   CC(=O)C#CC#C  0.379496      0  2.270287e+06\n",
       "5    CC(=O)CCC=O  0.359844      0  2.270297e+06\n",
       "6   NC(=O)CC1CC1  0.358055      0  2.270300e+06\n",
       "7     C1NC11COC1  0.356743      0  2.270301e+06"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b0bad",
   "metadata": {},
   "source": [
    "## Train a machine learning model to screen candidate molecules\n",
    "Our next step is to create a machine learning model to estimate the outcome of new computations (i.e., ionization energy) and use it to rapidly scan the search space.\n",
    "\n",
    "To start, let's make a function that uses our prior simulations to train a model. We are going to use RDKit and scikit-learn to train a nearest-neighbor model that uses Morgan fingerprints to define similarity (see [notes from a UChicago AI course](https://github.com/WardLT/applied-ai-for-materials/blob/main/molecular-property-prediction/chemoinformatics/2_ml-with-fingerprints.ipynb) for more detail). In short, the function trains a model that first populates a list of certain substructures (Morgan fingerprints, specifically) and then trains a model which predicts the IE of a new molecule by averaging those with the most similar substructures.\n",
    "\n",
    "We want to use Parsl here to scale the model and to later combine it into our ML-in-the-loop workflow. To do so, we define the function using `python_app`. This time, `python_app` is used as a decorator directly on the function definition (earlier we defined a regular function, and then applied `python_app` afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21fc424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def train_model(train_data):\n",
    "    \"\"\"Train a machine learning model using Morgan Fingerprints.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Dataframe with a 'smiles' and 'ie' column\n",
    "            that contains molecule structure and property, respectfully.\n",
    "    Returns:\n",
    "        A trained model\n",
    "    \"\"\"\n",
    "    # Imports for python functions run remotely must be defined inside the function\n",
    "    from chemfunctions import MorganFingerprintTransformer\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('fingerprint', MorganFingerprintTransformer()),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=4, weights='distance', metric='jaccard', n_jobs=-1))  # n_jobs = -1 lets the model run all available processors\n",
    "    ])\n",
    "    \n",
    "    return model.fit(train_data['smiles'], train_data['ie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd238446",
   "metadata": {},
   "source": [
    "## Train a machine learning model to screen candidate molecules\n",
    "\n",
    "The following function train_model2() uses prior simulations to train a model. It uses the RDKit and scikit-learn to train a nearest-neighbor model that uses 15 PCs of 208 RDKit decriptors to define similarity. In short, the function trains a model that first populates a list of certain substructures (15 PCs of 208 RDKit decriptors, specifically) and then trains a model which predicts the IE of a new molecule by averaging those with the most similar substructures.\n",
    "\n",
    "We want to use Parsl here to scale the model and to later combine it into our ML-in-the-loop workflow. To do so, we define the function using `python_app`. This time, `python_app` is used as a decorator directly on the function definition (earlier we defined a regular function, and then applied `python_app` afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef457b29-7120-42db-80f0-0633b453af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def train_model2(train_data):\n",
    "    \"\"\"Train a machine learning model using Morgan Fingerprints.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Dataframe with a 'smiles' and 'ie' column\n",
    "            that contains molecule structure and property, respectfully.\n",
    "    Returns:\n",
    "        A trained model\n",
    "    \"\"\"\n",
    "    # Imports for python functions run remotely must be defined inside the function\n",
    "    from chemfunctions import RDKitDescriptor2pcsTransformer\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('fingerprint', RDKitDescriptor2pcsTransformer()),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=4, weights='distance', metric='jaccard', n_jobs=-1))  # n_jobs = -1 lets the model run all available processors\n",
    "    ])\n",
    "    \n",
    "    return model.fit(train_data['smiles'], train_data['ie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0881389",
   "metadata": {},
   "source": [
    "## Train a machine learning model to screen candidate molecules\n",
    "\n",
    "The following function train_model_gpr() uses prior simulations to train a model. It uses the RDKit and scikit-learn to train a Gaussian process regression (GPR) model that uses 15 PCs of 208 RDKit decriptors to predicts the IE of a new molecule.\n",
    "\n",
    "We want to use Parsl here to scale the model and to later combine it into our ML-in-the-loop workflow. To do so, we define the function using `python_app`. This time, `python_app` is used as a decorator directly on the function definition (earlier we defined a regular function, and then applied `python_app` afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28863174-1a12-40d7-a8c6-c2cfac973440",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def train_model_gpr(train_data):\n",
    "    \"\"\"Train a machine learning model using Morgan Fingerprints.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Dataframe with a 'smiles' and 'ie' column\n",
    "            that contains molecule structure and property, respectfully.\n",
    "    Returns:\n",
    "        A trained model\n",
    "    \"\"\"\n",
    "    # Imports for python functions run remotely must be defined inside the function\n",
    "    # from chemfunctions import MorganFingerprintTransformer\n",
    "    \n",
    "    # Implemenet  RDKitDescriptorTransformer()\n",
    "    from chemfunctions import RDKitDescriptor2pcsTransformer\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "    from sklearn.gaussian_process.kernels import ConstantKernel as C ,WhiteKernel as Wht,Matern as matk\n",
    "\n",
    "    cmean=1.0\n",
    "    cbound=[1e-3, 1e3]\n",
    "    kernel = C(1.0, (1e-3,1e3)) * matk(cmean,cbound,1.5) + Wht(1.0, (1e-3, 1e3))  # Matern kernel\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, normalize_y=False)\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('fingerprint', RDKitDescriptor2pcsTransformer()),\n",
    "        ('gpr', GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, normalize_y=False))\n",
    "        ])\n",
    "    \n",
    "    return model.fit(train_data['smiles'], train_data['ie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88918a",
   "metadata": {},
   "source": [
    "Now let's execute the function and run it asynchronously with Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb0ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_future = train_model(train_data)\n",
    "train_future = train_model_gpr(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986e1b6",
   "metadata": {},
   "source": [
    "One of the unique features of Parsl is that it can create workflows on-the-fly directly from Python. Parsl workflows are chains of functions, connected by dynamic depencies (i.e., data passed between Parsl `apps`), that can run in parallel when possible.\n",
    "\n",
    "To establish the workflow, we pass the future created by executing one function an input to another Parsl function.\n",
    "\n",
    "As an example, let's create a function that uses the trained model to run inference on a large set of molecules and then another that takes many predictions and concatenates them into a single collection. The sequential workflow is implemented as follows.\n",
    "\n",
    "        train_model --> run_model --> combine_inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e947854",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def run_model(model, smiles):\n",
    "    \"\"\"Run a model on a list of smiles strings\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model that takes SMILES strings as inputs\n",
    "        smiles: List of molecules to evaluate\n",
    "    Returns:\n",
    "        A dataframe with the molecules and their predicted outputs\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    pred_y = model.predict(smiles)\n",
    "    return pd.DataFrame({'smiles': smiles, 'ie': pred_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4030e36",
   "metadata": {},
   "source": [
    "# Bayesian Optimization based Active Learning to sample new molecules for IE calculations\n",
    "## We will select 5 molecules that have highest Acquisition functions (AF)\n",
    "## available AF are Expected Improvement (EI), Probability of Improvement (PoI), and Upper confidence bound (UCB)\n",
    "## Default AF is EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de3cf715-063f-4327-892e-0cd4a6b02665",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def run_model_gpr(model, smiles,best_y=np.max(train_data['ie']),af=\"EI\"):\n",
    "    \"\"\"Run a model on a list of smiles strings\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model that takes SMILES strings as inputs\n",
    "        smiles: List of molecules to evaluate\n",
    "    Returns:\n",
    "        A dataframe with the molecules and their predicted outputs\n",
    "    \"\"\"\n",
    "    # Acquisition functions\n",
    "    def upperConfidenceBound(pred_y,sigma_y,epsilon=0.01):\n",
    "        \"\"\"\n",
    "            xdata: input feature vectors or PCs of the REMAINING set\n",
    "            gpnetwork: GPR model\n",
    "            epsilon: control exploration/exploitation. Higher epsilon means more exploration\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        ucb = np.empty(pred_y.size, dtype=float)\n",
    "        for ii in range(0,pred_y.size):\n",
    "            if sigma_y[ii] > 0:\n",
    "                ucb[ii]=(pred_y[ii]+epsilon*sigma_y[ii])\n",
    "            else:\n",
    "                ucb[ii]=0.0\n",
    "        return ucb\n",
    "    \n",
    "    def probabilityOfImprovement(pred_y,sigma_y,epsilon=0.01,best_y=best_y):  \n",
    "        \"ybest: GPR-predicted best output property of the TRAINING set\"\n",
    "        import numpy as np\n",
    "        from scipy.stats import norm\n",
    "        poI =  np.empty(pred_y.size, dtype=float)\n",
    "        for ii in range(0,pred_y.size):\n",
    "            if sigma_y[ii] > 0:\n",
    "                zzval=(pred_y[ii]-best_y-epsilon)/float(sigma_y[ii])\n",
    "                poI[ii]=norm.cdf(zzval)\n",
    "            else:\n",
    "                poI[ii]=0.0\n",
    "        return poI\n",
    "        \n",
    "    def expectedimprovement(pred_y,sigma_y,epsilon=0.01,best_y=best_y,itag=1):\n",
    "        import numpy as np\n",
    "        from scipy.stats import norm\n",
    "        expI =  np.empty(pred_y.size, dtype=float)\n",
    "        for ii in range(0,pred_y.size):\n",
    "            if sigma_y[ii] > 0:\n",
    "                zzval=itag*(pred_y[ii]-best_y)/float(sigma_y[ii])\n",
    "                expI[ii]=itag*(pred_y[ii]-best_y-epsilon)*norm.cdf(zzval)+sigma_y[ii]*norm.pdf(zzval)\n",
    "            else:\n",
    "                expI[ii]=0.0\n",
    "        return expI\n",
    "    \n",
    "    import pandas as pd\n",
    "    from scipy.stats import norm\n",
    "    pred_y,sigma_y = model.predict(smiles, return_std=True)\n",
    "    \n",
    "    # expI=EI(pred_y,sigma_y,best_y,itag=1,epsilon=0.01)\n",
    "    if af==\"UCB\":\n",
    "        AF=upperConfidenceBound(pred_y=pred_y,sigma_y=sigma_y,epsilon=0.01)\n",
    "    elif af==\"PoI\":\n",
    "        AF=probabilityOfImprovement(pred_y=pred_y,sigma_y=sigma_y,epsilon=0.01,best_y=best_y)\n",
    "    else:\n",
    "        AF=expectedimprovement(pred_y=pred_y,sigma_y=sigma_y,epsilon=0.01,best_y=best_y,itag=1)\n",
    "\n",
    "    return pd.DataFrame({'smiles': smiles, 'ie': pred_y, 'ie_sigma':sigma_y,'AF':AF})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fa1b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def combine_inferences(inputs=[]):\n",
    "    \"\"\"Concatenate a series of inferences into a single DataFrame\n",
    "    Args:\n",
    "        inputs: a list of the component DataFrames\n",
    "    Returns:\n",
    "        A single DataFrame containing the same inferences\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    return pd.concat(inputs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b350ea4",
   "metadata": {},
   "source": [
    "Now we've created our Parsl `apps`, we can chop up the search space into chunks, and invoke `run_model`  once for each chunk of the search space.\n",
    "\n",
    "Note: we pass `train_future` (the future created from the training function above) as input to `run_model`. Parsl will wait for the training to be complete (i.e., the future to be resolved) before executing `run_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f327013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the search space into smaller pieces, so that each can run in parallel\n",
    "chunks = np.array_split(search_space['smiles'], 64)\n",
    "best_in_ytrain=np.max(train_data['ie'])\n",
    "# inference_futures = [run_model(train_future, chunk) for chunk in chunks]\n",
    "inference_futures = [run_model_gpr(train_future, chunk,best_y=best_in_ytrain) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008cc2d",
   "metadata": {},
   "source": [
    "While we are running inferences in parallel we can define the final part of the workflow to combine results into a single DataFrame using `combine_inferences`.\n",
    "\n",
    "We pass the `inference_futures` as inputs to `combine_inferences` such that Parsl knows to establish a dependency between these two functions. That is, Parsl will ensure that `train_future` must complete before any of the `run_model` tasks start; and all of the `run_model` tasks must be finished before `combine_inferences` starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4135687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pass the inputs explicitly as a named argument \"inputs\" for Parsl to recognize this as a \"reduce\" step\n",
    "#  See: https://parsl.readthedocs.io/en/stable/userguide/workflow.html#mapreduce\n",
    "predictions = combine_inferences(inputs=inference_futures).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb78992",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "After completing the inference process we now have predicted IE values for all molecules in our search space. We can print out the best (highest AF) five molecules, according to the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9801c685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>ie</th>\n",
       "      <th>ie_sigma</th>\n",
       "      <th>AF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>OC1=CC=CC=C1</td>\n",
       "      <td>0.359014</td>\n",
       "      <td>0.052166</td>\n",
       "      <td>0.008681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>CC(C[NH3+])C([O-])=O</td>\n",
       "      <td>0.360376</td>\n",
       "      <td>0.041801</td>\n",
       "      <td>0.005594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>[NH3+]CCC([O-])=O</td>\n",
       "      <td>0.360428</td>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.005576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>FC(F)(F)F</td>\n",
       "      <td>0.361837</td>\n",
       "      <td>0.039377</td>\n",
       "      <td>0.005164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>NC1=CC=CC=C1</td>\n",
       "      <td>0.361105</td>\n",
       "      <td>0.039220</td>\n",
       "      <td>0.004945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    smiles        ie  ie_sigma        AF\n",
       "917           OC1=CC=CC=C1  0.359014  0.052166  0.008681\n",
       "1608  CC(C[NH3+])C([O-])=O  0.360376  0.041801  0.005594\n",
       "261      [NH3+]CCC([O-])=O  0.360428  0.041708  0.005576\n",
       "178              FC(F)(F)F  0.361837  0.039377  0.005164\n",
       "908           NC1=CC=CC=C1  0.361105  0.039220  0.004945"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions.sort_values('ie', ascending=False).head(5)\n",
    "predictions.sort_values('AF', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13b4ab",
   "metadata": {},
   "source": [
    "We have now created a Parsl workflow that is able to train a model and use it to identify molecules that are likely to be good next choices for simulations. Time to build a model-in-the-loop workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad296c",
   "metadata": {},
   "source": [
    "## Model-in-the-Loop Workflow\n",
    "We are going to build an application that uses a machine learning model to pick a batch of simulations, runs the simulations in parallel, and then uses the data to retrain the model before repeating the loop.\n",
    "\n",
    "Our application uses `train_model`, `run_model`, and `combine_inferences` as above, but after running an iteration it picks the predicted best molecules and runs the `compute_vertical_app` to run the xTB simulation.  The workflow then repeatedly retrains the model using these results until a fixed number of molecule simulations have been trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50007b1d-b094-4933-8140-97c321e2ea9f",
   "metadata": {},
   "source": [
    "Make the search space a list so that we can remove completed molecules more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9dc018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25ce1278123407fa5d70ac1da6de6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest IE in the batch 1 = 0.36606334320601214\n",
      "Highest IE in the batch 2 = 0.6315006899852438\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=search_count) as prog_bar: # setup a graphical progress bar\n",
    "    # Mark when we started\n",
    "    start_time = monotonic()\n",
    "    \n",
    "    # Submit with some random guesses\n",
    "    train_data = []\n",
    "    init_mols = search_space.sample(initial_count)['smiles']\n",
    "    sim_futures = [compute_vertical_app(mol) for mol in init_mols]\n",
    "    already_ran = set()\n",
    "    \n",
    "    # Loop until you finish populating the initial set\n",
    "    while len(sim_futures) > 0: \n",
    "        # First, get the next completed computation from the list\n",
    "        future = next(as_completed(sim_futures))\n",
    "\n",
    "        # Remove it from the list of still-running tasks\n",
    "        sim_futures.remove(future)\n",
    "\n",
    "        # Get the input \n",
    "        smiles = future.task_def['args'][0]\n",
    "        already_ran.add(smiles)\n",
    "\n",
    "        # Check if the run completed successfully\n",
    "        if future.exception() is not None:\n",
    "            # If it failed, pick a new SMILES string at random and submit it    \n",
    "            smiles = search_space.sample(1).iloc[0]['smiles'] # pick one molecule\n",
    "            new_future = compute_vertical_app(smiles) # launch a simulation in Parsl\n",
    "            sim_futures.append(new_future) # store the Future so we can keep track of it\n",
    "        else:\n",
    "            # If it succeeded, store the result\n",
    "            prog_bar.update(1)\n",
    "            train_data.append({\n",
    "                'smiles': smiles,\n",
    "                'ie': future.result(),\n",
    "                'batch': 0,\n",
    "                'time': monotonic() - start_time\n",
    "            })\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create the initial training set as a \n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    # best_in_ytrain=np.max(train_data['ie'])\n",
    "    # print(f\"Highest IE in the initial training dataset = {best_in_ytrain}\")\n",
    "    # Loop until complete\n",
    "    batch = 1\n",
    "    while len(train_data) < search_count:\n",
    "        best_in_ytrain=np.max(train_data['ie'])\n",
    "        print(f\"Highest IE in the batch {batch} = {best_in_ytrain}\")\n",
    "        # Train and predict as show in the previous section.\n",
    "        train_future = train_model_gpr(train_data)\n",
    "        # inference_futures = [run_model(train_future, chunk) for chunk in np.array_split(search_space['smiles'], 64)]\n",
    "        inference_futures = [run_model_gpr(train_future, chunk,best_y=best_in_ytrain) for chunk in np.array_split(search_space['smiles'], 64)]\n",
    "        predictions = combine_inferences(inputs=inference_futures).result()\n",
    "\n",
    "        # Sort the predictions in descending order, and submit new molecules from them\n",
    "        # predictions.sort_values('ie', ascending=False, inplace=True)\n",
    "        predictions.sort_values('AF', ascending=False, inplace=True)\n",
    "        sim_futures = []\n",
    "        for smiles in predictions['smiles']:\n",
    "            if smiles not in already_ran:\n",
    "                sim_futures.append(compute_vertical_app(smiles))\n",
    "                already_ran.add(smiles)\n",
    "                if len(sim_futures) >= batch_size:\n",
    "                    break\n",
    "\n",
    "        # Wait for every task in the current batch to complete, and store successful results\n",
    "        new_results = []\n",
    "        for future in as_completed(sim_futures):\n",
    "            if future.exception() is None:\n",
    "                prog_bar.update(1)\n",
    "                new_results.append({\n",
    "                    'smiles': future.task_def['args'][0],\n",
    "                    'ie': future.result(),\n",
    "                    'batch': batch, \n",
    "                    'time': monotonic() - start_time\n",
    "                })\n",
    "                \n",
    "        # Update the training data and repeat\n",
    "        batch += 1\n",
    "        train_data = pd.concat((train_data, pd.DataFrame(new_results)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66fd64b",
   "metadata": {},
   "source": [
    "We can plot the training data against the time of simulation, showing that the model is finding better molecules over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b774aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 324x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.5, 3.))\n",
    "\n",
    "ax.scatter(train_data['time'], train_data['ie'])\n",
    "ax.step(train_data['time'], train_data['ie'].cummax(), 'k--')\n",
    "\n",
    "ax.set_xlabel('Walltime (s)')\n",
    "ax.set_ylabel('Ion. Energy (Ha)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3930b49-cf7e-405a-bdf9-dd332addbeb6",
   "metadata": {},
   "source": [
    "Save that data for comparison with another application later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c295545-8f4c-476a-9300-cdc132add9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('run-data/parsl-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccafdc-343a-47b6-a4b8-b712386e41e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "00a5131b94e1651b60ec524aa15e233bc471fcc5f68e93d7def1029cb997c5c0"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0cacceed9db4464f9f414274519b4949": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "252de14e22c54080bfcaff0574d898d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "270ad7c288c14ba2af5fe1cd642a09eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6fe9c731cdc640ad858660f64c387dc4",
       "placeholder": "",
       "style": "IPY_MODEL_fe7006dbf4824d898f4f010f87b1c6f2",
       "value": " 70/? [01:05&lt;00:00,  1.26s/it]"
      }
     },
     "474ddeec4b9e40f5a89f9c7b67ea31e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0cacceed9db4464f9f414274519b4949",
       "placeholder": "",
       "style": "IPY_MODEL_d4c9ca989df549f09c7ce94ee74c6a57",
       "value": ""
      }
     },
     "6fe9c731cdc640ad858660f64c387dc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "84f635e5b62a44c0b110315fb375c321": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad75de48e1324ca3993fc8cf8b31a853",
       "max": 64,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_252de14e22c54080bfcaff0574d898d4",
       "value": 64
      }
     },
     "91420bed062b46e9b5c2a914377ed68f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad75de48e1324ca3993fc8cf8b31a853": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb5f4153b6a44eac8cec5ed6fc6923ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_474ddeec4b9e40f5a89f9c7b67ea31e6",
        "IPY_MODEL_84f635e5b62a44c0b110315fb375c321",
        "IPY_MODEL_270ad7c288c14ba2af5fe1cd642a09eb"
       ],
       "layout": "IPY_MODEL_91420bed062b46e9b5c2a914377ed68f"
      }
     },
     "d4c9ca989df549f09c7ce94ee74c6a57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fe7006dbf4824d898f4f010f87b1c6f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
